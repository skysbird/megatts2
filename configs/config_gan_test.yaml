# lightning.pytorch==2.1.0
seed_everything: true
trainer:
  logger:
    class_path: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: logs/
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: 3
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val/loss_re
        filename: gan_ar_checkpoint_{epoch}_{step}
        save_top_k: 5
        save_last: true
        every_n_epochs: 1
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  # ~ 3 epochs
  max_steps: 600000
  # # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  # limit_val_batches: 100
  accelerator: gpu
  log_every_n_steps: 100
  # val_check_interval: 20
  check_val_every_n_epoch: 1000

  # strategy: ddp
  # devices: [0, 1]
  # use_distributed_sampler: false

  devices: [0]
model:
  G:
    class_path: models.gan.VQGANTTS
    init_args:
      content_encoder:
        class_path: new_modules.content_encoder.ContentEncoder
        init_args:
          d_model: 512
          nhead: 2
          num_encoder_layers: 8
          dim_feedforward: 1024
          dropout: 0.1
          kernel_size: 5
          vocab_size: 320
      mrte:
        class_path: new_modules.mrte.MRTE
        init_args:
          mel_dim: 80
          global_mel_dim: 80
          hidden_size: 512
          n_heads: 2
      vqpe:
        class_path: modules.vqpe.VQProsodyEncoder
        init_args:
          mel_bins: 80
          stride: 8
          hidden_size: 384
          kernel_size: 5
          n_stack: 3
          n_block: 2
          vq_bins: 1024
          vq_dim: 256
          activation: ReLU
      mel_decoder:
        class_path: modules.convnet.ConvNet
        init_args:
          in_channels: 1024 # 512 + 512
          out_channels: 80
          n_stacks: 4
          n_blocks: 2
          hidden_size: 512
          kernel_size: 5
          activation: 'ReLU'

  D:
    class_path: modules.dscrm.Discriminator
    init_args:
      time_lengths:
      - 32
      - 64
      - 128
      freq_length: 80
      kernel:
      - 3
      - 3
      c_in: 1
      hidden_size: 192
  initial_learning_rate: 3e-5
  warmup_steps: 200.0

  G_commit_loss_coeff: 0.15
  G_vq_loss_coeff: 0.05
  G_adv_loss_coeff: 1.0
  train_dtype: float32
  class_path: models.trainer.MegaGANTrainer
data:
  ds_path: /data/sky/data/ds/
  max_duration_batch: 60
  min_duration: 2.1
  max_duration: 20
  num_buckets: 2
  num_workers: 4
  class_path: modules.datamodule.TTSDataModule
ckpt_path: null
